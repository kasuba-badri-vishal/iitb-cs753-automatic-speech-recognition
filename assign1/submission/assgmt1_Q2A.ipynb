{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bKXIYTJSOnt_",
        "rtdr1VnyCQTJ"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PART I: Running a SpeechBrain ASR Recipe"
      ],
      "metadata": {
        "id": "p3S0Etz_Nokz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## You have to fill in appropriate code in 4 locations in the notebook.\n",
        "\n",
        "* The four locations start with \"####TASK\". Read the task specifications mentioned there.\n",
        "* The required function names are already available in this notebook somewhere. You're only required to find and use the appropriate ones.\n",
        "* Check the SpeechBrain documentation to find out how to use those functions. Refer to the starting material for more resources.\n",
        "* By the end of this part of the assignment, you should be comfortable running a Speechbrain recipe.\n",
        "* **P.S.** Note that none of the four tasks require you to write more than 1 line of code."
      ],
      "metadata": {
        "id": "h-xktzpeEBjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the codebase."
      ],
      "metadata": {
        "id": "bKXIYTJSOnt_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "A5H2lpHX7npZ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Clone SpeechBrain repository\n",
        "!git clone https://github.com/Darshan7575/speechbrain.git\n",
        "%cd /content/speechbrain/\n",
        "\n",
        "# Install required dependencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Install SpeechBrain in editable mode\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Required imports\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import logging\n",
        "import sys\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import speechbrain as sb\n",
        "from hyperpyyaml import load_hyperpyyaml\n",
        "from speechbrain.utils.data_utils import get_all_files, download_file\n",
        "from speechbrain.dataio.dataio import read_audio\n",
        "from speechbrain.utils.distributed import run_on_main, if_main_process\n",
        "\n",
        "# Required variables and loggers\n",
        "logger = logging.getLogger(__name__)\n",
        "logger = logging.getLogger(__name__)\n",
        "MINILIBRI_TRAIN_URL = \"http://www.openslr.org/resources/31/train-clean-5.tar.gz\"\n",
        "MINILIBRI_VALID_URL = \"http://www.openslr.org/resources/31/dev-clean-2.tar.gz\"\n",
        "MINILIBRI_TEST_URL = \"https://www.openslr.org/resources/12/test-clean.tar.gz\"\n",
        "SAMPLERATE = 16000\n",
        "\n",
        "device=\"cuda\"\n",
        "run_opts = {'device':device}"
      ],
      "metadata": {
        "id": "61C_gxJo5aRH"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer Training\n",
        "In this section, we will train a BPE tokenizer with **150 tokens** using `Sentencepiece`.\n",
        "\n"
      ],
      "metadata": {
        "id": "rtdr1VnyCQTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ############################################################################\n",
        "# Dataset creation helper functions\n",
        "# ############################################################################\n",
        "\n",
        "def prepare_mini_librispeech(\n",
        "    data_folder, save_json_train, save_json_valid, save_json_test\n",
        "):\n",
        "    \"\"\"\n",
        "    Prepares the json files for the Mini Librispeech dataset.\n",
        "    Downloads the dataset if its not found in the `data_folder`.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if this phase is already done (if so, skip it)\n",
        "    if skip(save_json_train, save_json_valid, save_json_test):\n",
        "        logger.info(\"Preparation completed in previous run, skipping.\")\n",
        "        return\n",
        "\n",
        "    # If the dataset doesn't exist yet, download it\n",
        "    train_folder = os.path.join(data_folder, \"LibriSpeech\", \"train-clean-5\")\n",
        "    valid_folder = os.path.join(data_folder, \"LibriSpeech\", \"dev-clean-2\")\n",
        "    test_folder = os.path.join(data_folder, \"LibriSpeech\", \"test-clean\")\n",
        "    if not check_folders(train_folder, valid_folder, test_folder):\n",
        "        download_mini_librispeech(data_folder)\n",
        "\n",
        "    # List files and create manifest from list\n",
        "    logger.info(\n",
        "        f\"Creating {save_json_train}, {save_json_valid}, and {save_json_test}\"\n",
        "    )\n",
        "    extension = [\".flac\"]\n",
        "\n",
        "    # List of flac audio files\n",
        "    wav_list_train = get_all_files(train_folder, match_and=extension)\n",
        "    wav_list_valid = get_all_files(valid_folder, match_and=extension)\n",
        "    wav_list_test = get_all_files(test_folder, match_and=extension)\n",
        "\n",
        "    # List of transcription file\n",
        "    extension = [\".trans.txt\"]\n",
        "    trans_list = get_all_files(data_folder, match_and=extension)\n",
        "    trans_dict = get_transcription(trans_list)\n",
        "\n",
        "    # Create the json files\n",
        "    create_json(wav_list_train, trans_dict, save_json_train)\n",
        "    create_json(wav_list_valid, trans_dict, save_json_valid)\n",
        "    create_json(wav_list_test, trans_dict, save_json_test)\n",
        "\n",
        "\n",
        "def get_transcription(trans_list):\n",
        "    \"\"\"\n",
        "    Returns a dictionary with the transcription of each sentence in the dataset.\n",
        "    \"\"\"\n",
        "    # Processing all the transcription files in the list\n",
        "    trans_dict = {}\n",
        "    for trans_file in trans_list:\n",
        "        # Reading the text file\n",
        "        with open(trans_file) as f:\n",
        "            for line in f:\n",
        "                uttid = line.split(\" \")[0]\n",
        "                text = line.rstrip().split(\" \")[1:]\n",
        "                text = \" \".join(text)\n",
        "                trans_dict[uttid] = text\n",
        "\n",
        "    logger.info(\"Transcription files read!\")\n",
        "    return trans_dict\n",
        "\n",
        "\n",
        "def create_json(wav_list, trans_dict, json_file):\n",
        "    \"\"\"\n",
        "    Creates the json file given a list of wav files and their transcriptions.\n",
        "    \"\"\"\n",
        "    # Processing all the wav files in the list\n",
        "    json_dict = {}\n",
        "    for wav_file in wav_list:\n",
        "\n",
        "        # Reading the signal (to retrieve duration in seconds)\n",
        "        signal = read_audio(wav_file)\n",
        "        duration = signal.shape[0] / SAMPLERATE\n",
        "\n",
        "        # Manipulate path to get relative path and uttid\n",
        "        path_parts = wav_file.split(os.path.sep)\n",
        "        uttid, _ = os.path.splitext(path_parts[-1])\n",
        "        relative_path = os.path.join(\"{data_root}\", *path_parts[-5:])\n",
        "\n",
        "        # Create entry for this utterance\n",
        "        json_dict[uttid] = {\n",
        "            \"wav\": relative_path,\n",
        "            \"length\": duration,\n",
        "            \"words\": trans_dict[uttid],\n",
        "        }\n",
        "\n",
        "    # Writing the dictionary to the json file\n",
        "    with open(json_file, mode=\"w\") as json_f:\n",
        "        json.dump(json_dict, json_f, indent=2)\n",
        "\n",
        "    logger.info(f\"{json_file} successfully created!\")\n",
        "\n",
        "\n",
        "def skip(*filenames):\n",
        "    \"\"\"\n",
        "    Detects if the data preparation has been already done.\n",
        "    If the preparation has been done, we can skip it.\n",
        "    \"\"\"\n",
        "    for filename in filenames:\n",
        "        if not os.path.isfile(filename):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def check_folders(*folders):\n",
        "    \"\"\"Returns False if any passed folder does not exist.\"\"\"\n",
        "    for folder in folders:\n",
        "        if not os.path.exists(folder):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def download_mini_librispeech(destination):\n",
        "    \"\"\"Download dataset and unpack it.\n",
        "    \"\"\"\n",
        "    train_archive = os.path.join(destination, \"train-clean-5.tar.gz\")\n",
        "    valid_archive = os.path.join(destination, \"dev-clean-2.tar.gz\")\n",
        "    test_archive = os.path.join(destination, \"test-clean.tar.gz\")\n",
        "    download_file(MINILIBRI_TRAIN_URL, train_archive)\n",
        "    download_file(MINILIBRI_VALID_URL, valid_archive)\n",
        "    download_file(MINILIBRI_TEST_URL, test_archive)\n",
        "    shutil.unpack_archive(train_archive, destination)\n",
        "    shutil.unpack_archive(valid_archive, destination)\n",
        "    shutil.unpack_archive(test_archive, destination)"
      ],
      "metadata": {
        "id": "ujToJHWC4T5y"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_hyperparams = \"\"\"\n",
        "# ############################################################################\n",
        "# Tokenizer: subword BPE with unigram 150\n",
        "# ############################################################################\n",
        "\n",
        "output_folder: !ref results/tokenizer/\n",
        "\n",
        "# Data files\n",
        "data_folder: data\n",
        "train_annotation: !ref <data_folder>/train.json\n",
        "valid_annotation: !ref <data_folder>/valid.json\n",
        "test_annotation: !ref <data_folder>/test.json\n",
        "\n",
        "# Tokenizer training parameters\n",
        "token_type: unigram  # [\"unigram\", \"bpe\", \"char\"]\n",
        "token_output: 150  # index(blank/eos/bos/unk) = 0\n",
        "character_coverage: 1.0\n",
        "json_read: words\n",
        "\n",
        "tokenizer: !name:speechbrain.tokenizers.SentencePiece.SentencePiece\n",
        "   model_dir: !ref <output_folder>\n",
        "   vocab_size: !ref <token_output>\n",
        "   annotation_train: !ref <train_annotation>\n",
        "   annotation_read: !ref <json_read>\n",
        "   annotation_format: json\n",
        "   model_type: !ref <token_type> # [\"unigram\", \"bpe\", \"char\"]\n",
        "   character_coverage: !ref <character_coverage>\n",
        "   annotation_list_to_check: [!ref <train_annotation>, !ref <valid_annotation>]\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rz9pyHan4V0S"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load required params from the hyperpyyaml file\n",
        "hparams = load_hyperpyyaml(tokenizer_hyperparams)\n",
        "\n",
        "# 1. Dataset creation\n",
        "\n",
        "## Create experiment directory\n",
        "sb.create_experiment_directory(\n",
        "    experiment_directory=hparams[\"output_folder\"],\n",
        "    overrides=None,\n",
        ")\n",
        "\n",
        "## Create dataset\n",
        "run_on_main(\n",
        "    prepare_mini_librispeech,\n",
        "    kwargs={\n",
        "        \"data_folder\": hparams[\"data_folder\"],\n",
        "        \"save_json_train\": hparams[\"train_annotation\"],\n",
        "        \"save_json_valid\": hparams[\"valid_annotation\"],\n",
        "        \"save_json_test\": hparams[\"test_annotation\"],\n",
        "    },\n",
        ")\n",
        "\n",
        "# 2. Tokenizer training\n",
        "hparams[\"tokenizer\"]()\n",
        "\n",
        "# 3. Saving tokenizer in .ckpt extension\n",
        "output_path = hparams[\"output_folder\"]\n",
        "token_output = hparams[\"token_output\"]\n",
        "token_type = hparams[\"token_type\"]\n",
        "bpe_model = f\"{output_path}/{token_output}_{token_type}.model\"\n",
        "tokenizer_ckpt = f\"{output_path}/tokenizer.ckpt\"\n",
        "shutil.copyfile(bpe_model, tokenizer_ckpt)"
      ],
      "metadata": {
        "id": "nA8xD6Do4Xl7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "27947756-ec98-4294-abe8-3a38bc078921"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/tokenizer/\n",
            "__main__ - Preparation completed in previous run, skipping.\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer is already trained.\n",
            "speechbrain.tokenizers.SentencePiece - ==== Loading Tokenizer ===\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer path: results/tokenizer/150_unigram.model\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer vocab_size: 150\n",
            "speechbrain.tokenizers.SentencePiece - Tokenizer type: unigram\n",
            "speechbrain.tokenizers.SentencePiece - ==== Accuracy checking for recovering text from tokenizer ===\n",
            "speechbrain.tokenizers.SentencePiece - recover words from: data/train.json\n",
            "speechbrain.tokenizers.SentencePiece - Wrong recover words: 0\n",
            "speechbrain.tokenizers.SentencePiece - accuracy recovering words: 1.0\n",
            "speechbrain.tokenizers.SentencePiece - ==== Accuracy checking for recovering text from tokenizer ===\n",
            "speechbrain.tokenizers.SentencePiece - recover words from: data/valid.json\n",
            "speechbrain.tokenizers.SentencePiece - Wrong recover words: 0\n",
            "speechbrain.tokenizers.SentencePiece - accuracy recovering words: 1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'results/tokenizer//tokenizer.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training\n",
        "In this section, we will train a **6 layer Conformer** encoder only architecture with the `CTC objective`."
      ],
      "metadata": {
        "id": "vwqFx3QcOdd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_hyperparams = \"\"\"\n",
        "# Seed needs to be set at top of yaml, before objects with parameters are made\n",
        "seed: 2024\n",
        "__set_seed: !apply:torch.manual_seed [!ref <seed>]\n",
        "\n",
        "# Data files\n",
        "data_folder: data\n",
        "\n",
        "####TASK ADD APPROPRIATE REFERENCES TO LOAD THE FILES ##############\n",
        "\n",
        "train_annotation: !ref <data_folder>/train.json\n",
        "valid_annotation: !ref <data_folder>/valid.json\n",
        "test_annotation: !ref <data_folder>/test.json\n",
        "#####################################################################\n",
        "\n",
        "# Language model (LM) pretraining\n",
        "pretrained_lm_tokenizer_path: ./results/tokenizer\n",
        "\n",
        "# Training parameters\n",
        "number_of_epochs: 30\n",
        "batch_size: 8\n",
        "lr_adam: 0.001\n",
        "max_grad_norm: 5.0\n",
        "ckpt_interval_minutes: 15 # save checkpoint every N min\n",
        "loss_reduction: 'batchmean'\n",
        "\n",
        "# Dataloader options\n",
        "train_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "valid_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "test_dataloader_opts:\n",
        "    batch_size: !ref <batch_size>\n",
        "\n",
        "# Feature parameters\n",
        "sample_rate: 16000\n",
        "n_fft: 400\n",
        "n_mels: 80\n",
        "\n",
        "####################### Model parameters ###########################\n",
        "# Transformer\n",
        "d_model: 64\n",
        "nhead: 4\n",
        "num_encoder_layers: 6\n",
        "d_ffn: 256\n",
        "transformer_dropout: 0.1\n",
        "activation: !name:torch.nn.GELU\n",
        "output_neurons: 150\n",
        "label_smoothing: 0.0\n",
        "attention_type: RelPosMHAXL\n",
        "\n",
        "# Outputs\n",
        "blank_index: 0\n",
        "pad_index: 0\n",
        "bos_index: 1\n",
        "eos_index: 2\n",
        "\n",
        "# Decoding parameters\n",
        "min_decode_ratio: 0.0\n",
        "max_decode_ratio: 1.0\n",
        "test_beam_size: 1\n",
        "ctc_weight_decode: 1.0\n",
        "\n",
        "############################## models ################################\n",
        "\n",
        "compute_features: !new:speechbrain.lobes.features.Fbank\n",
        "    sample_rate: !ref <sample_rate>\n",
        "    n_fft: !ref <n_fft>\n",
        "    n_mels: !ref <n_mels>\n",
        "\n",
        "CNN: !new:speechbrain.lobes.models.convolution.ConvolutionFrontEnd\n",
        "    input_shape: (8, 10, 80)\n",
        "    num_blocks: 2\n",
        "    num_layers_per_block: 1\n",
        "    out_channels: (64, 32)\n",
        "    kernel_sizes: (3, 3)\n",
        "    strides: (2, 2)\n",
        "    residuals: (False, False)\n",
        "\n",
        "# standard parameters for the BASE model\n",
        "Transformer: !new:speechbrain.lobes.models.transformer.TransformerASR.TransformerASR\n",
        "    input_size: 640\n",
        "    tgt_vocab: !ref <output_neurons>\n",
        "    d_model: !ref <d_model>\n",
        "    nhead: !ref <nhead>\n",
        "    num_encoder_layers: !ref <num_encoder_layers>\n",
        "    num_decoder_layers: 0\n",
        "    d_ffn: !ref <d_ffn>\n",
        "    dropout: !ref <transformer_dropout>\n",
        "    activation: !ref <activation>\n",
        "    encoder_module: conformer\n",
        "    attention_type: !ref <attention_type>\n",
        "    normalize_before: True\n",
        "\n",
        "tokenizer: !new:sentencepiece.SentencePieceProcessor\n",
        "\n",
        "ctc_lin: !new:speechbrain.nnet.linear.Linear\n",
        "    input_size: !ref <d_model>\n",
        "    n_neurons: !ref <output_neurons>\n",
        "\n",
        "normalize: !new:speechbrain.processing.features.InputNormalization\n",
        "    norm_type: global\n",
        "    update_until_epoch: 4\n",
        "\n",
        "modules:\n",
        "    CNN: !ref <CNN>\n",
        "    Transformer: !ref <Transformer>\n",
        "    ctc_lin: !ref <ctc_lin>\n",
        "    normalize: !ref <normalize>\n",
        "\n",
        "model: !new:torch.nn.ModuleList\n",
        "    - [!ref <CNN>, !ref <Transformer>, !ref <ctc_lin>]\n",
        "\n",
        "# define two optimizers here for two-stage training\n",
        "Adam: !name:torch.optim.Adam\n",
        "    lr: !ref <lr_adam>\n",
        "    betas: (0.9, 0.98)\n",
        "    eps: 0.000000001\n",
        "\n",
        "log_softmax: !new:torch.nn.LogSoftmax\n",
        "    dim: -1\n",
        "\n",
        "ctc_cost: !name:speechbrain.nnet.losses.ctc_loss\n",
        "    blank_index: !ref <blank_index>\n",
        "    reduction: !ref <loss_reduction>\n",
        "\n",
        "noam_annealing: !new:speechbrain.nnet.schedulers.NoamScheduler\n",
        "    lr_initial: !ref <lr_adam>\n",
        "    n_warmup_steps: 1500\n",
        "\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <number_of_epochs>\n",
        "\n",
        "error_rate_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats\n",
        "\n",
        "cer_computer: !name:speechbrain.utils.metric_stats.ErrorRateStats\n",
        "   split_tokens: True\n",
        "\n",
        "# The pretrainer allows a mapping between pretrained files and instances that\n",
        "# are declared in the yaml. E.g here, we will download the file tokenizer.ckpt\n",
        "# and it will be loaded into \"tokenizer\" which is pointing to the <pretrained_lm_tokenizer_path> defined\n",
        "# before.\n",
        "pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n",
        "    loadables:\n",
        "        tokenizer: !ref <tokenizer>\n",
        "    paths:\n",
        "        tokenizer: !ref <pretrained_lm_tokenizer_path>/tokenizer.ckpt\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "6WPcwXueCRm7"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataio_prepare(hparams):\n",
        "    \"\"\"This function prepares the datasets to be used in the brain class.\n",
        "    It also defines the data processing pipeline through user-defined functions.\n",
        "    \"\"\"\n",
        "    # Define audio pipeline. In this case, we simply read the path contained\n",
        "    # in the variable wav with the audio reader.\n",
        "    @sb.utils.data_pipeline.takes(\"wav\")\n",
        "    @sb.utils.data_pipeline.provides(\"sig\")\n",
        "    def audio_pipeline(wav):\n",
        "        \"\"\"Load the audio signal. This is done on the CPU in the `collate_fn`.\"\"\"\n",
        "        sig = sb.dataio.dataio.read_audio(wav)\n",
        "        return sig\n",
        "\n",
        "    tokenizer = hparams[\"tokenizer\"]\n",
        "    # Define text processing pipeline. We start from the raw text and then\n",
        "    # encode it using the tokenizer. The tokens with BOS are used for feeding\n",
        "    # decoder during training, the tokens with EOS for computing the cost function.\n",
        "    # The tokens without BOS or EOS is for computing CTC loss.\n",
        "    @sb.utils.data_pipeline.takes(\"words\")\n",
        "    @sb.utils.data_pipeline.provides(\n",
        "        \"wrd\", \"tokens_list\", \"tokens_bos\", \"tokens_eos\", \"tokens\"\n",
        "    )\n",
        "    def text_pipeline(wrd):\n",
        "        \"\"\"Processes the transcriptions to generate proper labels\"\"\"\n",
        "        yield wrd\n",
        "        tokens_list = tokenizer.encode_as_ids(wrd)\n",
        "        yield tokens_list\n",
        "        tokens_bos = torch.LongTensor([hparams[\"bos_index\"]] + (tokens_list))\n",
        "        yield tokens_bos\n",
        "        tokens_eos = torch.LongTensor(tokens_list + [hparams[\"eos_index\"]])\n",
        "        yield tokens_eos\n",
        "        tokens = torch.LongTensor(tokens_list)\n",
        "        yield tokens\n",
        "\n",
        "    # Define datasets from json data manifest file\n",
        "    # Define datasets sorted by ascending lengths for efficiency\n",
        "    datasets = {}\n",
        "    data_folder = hparams[\"data_folder\"]\n",
        "    for dataset in [\"train\", \"valid\", \"test\"]:\n",
        "        datasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_json(\n",
        "            json_path=hparams[f\"{dataset}_annotation\"],\n",
        "            replacements={\"data_root\": data_folder},\n",
        "            dynamic_items=[audio_pipeline, text_pipeline],\n",
        "            output_keys=[\n",
        "                \"id\",\n",
        "                \"sig\",\n",
        "                \"wrd\",\n",
        "                \"tokens_bos\",\n",
        "                \"tokens_eos\",\n",
        "                \"tokens\",\n",
        "            ],\n",
        "        )\n",
        "        hparams[f\"{dataset}_dataloader_opts\"][\"shuffle\"] = False\n",
        "\n",
        "    datasets[\"train\"] = datasets[\"train\"].filtered_sorted(sort_key=\"length\")\n",
        "    hparams[\"train_dataloader_opts\"][\"shuffle\"] = False\n",
        "\n",
        "    return (\n",
        "        datasets[\"train\"],\n",
        "        datasets[\"valid\"],\n",
        "        datasets[\"test\"],\n",
        "        tokenizer\n",
        "    )"
      ],
      "metadata": {
        "id": "euJMqDLSWv7Y"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training procedure\n",
        "class BaseASR(sb.Brain):\n",
        "    def __init__(\n",
        "        self,\n",
        "        modules=None,\n",
        "        opt_class=None,\n",
        "        hparams=None,\n",
        "        run_opts=None,\n",
        "        checkpointer=None,\n",
        "        profiler=None,\n",
        "        tokenizer=None,\n",
        "    ):\n",
        "        super(BaseASR, self).__init__(\n",
        "            modules=modules,\n",
        "            opt_class=opt_class,\n",
        "            hparams=hparams,\n",
        "            run_opts=run_opts,\n",
        "            checkpointer=checkpointer,\n",
        "            profiler=profiler\n",
        "        )\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"\"\"Performs a forward pass through the encoder\"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        wavs, wav_lens = batch.sig\n",
        "        tokens_bos, _ = batch.tokens_bos\n",
        "\n",
        "        # compute features\n",
        "        ####TASK MAKE APPROPRIATE FUNCTION CALLS TO COMPUTE THE FEATURES BELOW\n",
        "        feats = self.hparams.compute_features(wavs)\n",
        "        current_epoch = self.hparams.epoch_counter.current\n",
        "        feats = self.modules.normalize(feats, wav_lens, epoch=current_epoch)\n",
        "\n",
        "        # forward modules\n",
        "        src = self.modules.CNN(feats)\n",
        "\n",
        "        enc_out, _ = self.modules.Transformer(\n",
        "            src, tokens_bos, wav_lens, pad_idx=self.hparams.pad_index,\n",
        "        )\n",
        "\n",
        "        # output layer for ctc log-probabilities\n",
        "        logits = self.modules.ctc_lin(enc_out)\n",
        "\n",
        "        ####TASK CALCULATE THE PROBABILITIES OF THESE LOGITS\n",
        "        #### USING SPEECHBRAIN\n",
        "        p_ctc = self.hparams.log_softmax(logits)\n",
        "\n",
        "        # Compute outputs\n",
        "        hyps = None\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            hyps = None\n",
        "        else:\n",
        "            hyps = sb.decoders.ctc_greedy_decode(\n",
        "                p_ctc, wav_lens, blank_id=self.hparams.blank_index\n",
        "            )\n",
        "\n",
        "        return p_ctc, wav_lens, hyps\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"\"\"Computes the CTC loss given predictions and targets.\"\"\"\n",
        "\n",
        "        (p_ctc, wav_lens, hyps,) = predictions\n",
        "\n",
        "        ids = batch.id\n",
        "        tokens_eos, tokens_eos_lens = batch.tokens_eos\n",
        "        tokens, tokens_lens = batch.tokens\n",
        "\n",
        "        # Calculate CTC loss\n",
        "        ####TASK Make required function call to compute CTC LOSS\n",
        "        #### You have to aggregate the loss in the end so make appropriate\n",
        "        #### modifications to the value returned.\n",
        "        loss = self.hparams.ctc_cost(p_ctc, tokens, wav_lens, tokens_lens)\n",
        "\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            # Decode token terms to words\n",
        "            predicted_words = [\n",
        "                self.tokenizer.decode_ids(utt_seq).split(\" \") for utt_seq in hyps\n",
        "            ]\n",
        "            target_words = [wrd.split(\" \") for wrd in batch.wrd]\n",
        "            self.wer_metric.append(ids, predicted_words, target_words)\n",
        "            self.cer_metric.append(ids, predicted_words, target_words)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_evaluate_start(self, max_key=None, min_key=None):\n",
        "        \"\"\"Performs checkpoint averge if needed\"\"\"\n",
        "        super().on_evaluate_start()\n",
        "\n",
        "        ckpts = self.checkpointer.find_checkpoints(\n",
        "            max_key=max_key, min_key=min_key\n",
        "        )\n",
        "        ckpt = sb.utils.checkpoints.average_checkpoints(\n",
        "            ckpts, recoverable_name=\"model\", device=self.device\n",
        "        )\n",
        "\n",
        "        self.hparams.model.load_state_dict(ckpt, strict=True)\n",
        "        self.hparams.model.eval()\n",
        "        print(\"Loaded the average\")\n",
        "\n",
        "    def evaluate_batch(self, batch, stage):\n",
        "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
        "        with torch.no_grad():\n",
        "            predictions = self.compute_forward(batch, stage=stage)\n",
        "            loss = self.compute_objectives(predictions, batch, stage=stage)\n",
        "        return loss.detach()\n",
        "\n",
        "    def on_stage_start(self, stage, epoch):\n",
        "        \"\"\"Gets called at the beginning of each epoch\"\"\"\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            self.cer_metric = self.hparams.cer_computer()\n",
        "            self.wer_metric = self.hparams.error_rate_computer()\n",
        "\n",
        "    def on_stage_end(self, stage, stage_loss, epoch):\n",
        "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
        "        # Compute/store important stats\n",
        "        stage_stats = {\"loss\": stage_loss}\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            self.train_stats = stage_stats\n",
        "        else:\n",
        "            stage_stats[\"CER\"] = self.cer_metric.summarize(\"error_rate\")\n",
        "            stage_stats[\"WER\"] = self.wer_metric.summarize(\"error_rate\")\n",
        "\n",
        "        # log stats and save checkpoint at end-of-epoch\n",
        "        if stage == sb.Stage.VALID and sb.utils.distributed.if_main_process():\n",
        "\n",
        "            lr = self.hparams.noam_annealing.current_lr\n",
        "            steps = self.optimizer_step\n",
        "            optimizer = self.optimizer.__class__.__name__\n",
        "\n",
        "            epoch_stats = {\n",
        "                \"epoch\": epoch,\n",
        "                \"lr\": lr,\n",
        "                \"steps\": steps,\n",
        "                \"optimizer\": optimizer,\n",
        "            }\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta=epoch_stats,\n",
        "                train_stats=self.train_stats,\n",
        "                valid_stats=stage_stats,\n",
        "            )\n",
        "            # Save only last 10 checkpoints\n",
        "            self.checkpointer.save_and_keep_only(\n",
        "                meta={\"loss\": stage_loss, \"epoch\": epoch},\n",
        "                max_keys=[\"epoch\"],\n",
        "                num_to_keep=10,\n",
        "            )\n",
        "\n",
        "        elif stage == sb.Stage.TEST:\n",
        "            self.hparams.train_logger.log_stats(\n",
        "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
        "                test_stats=stage_stats,\n",
        "            )\n",
        "            # Write the WER metric for test dataset\n",
        "            if if_main_process():\n",
        "                with open(self.hparams.test_wer_file, \"w\") as w:\n",
        "                    self.wer_metric.write_stats(w)\n",
        "\n",
        "    def fit_batch(self, batch):\n",
        "        \"\"\"Performs a forward + backward pass on 1 batch\n",
        "        \"\"\"\n",
        "\n",
        "        should_step = self.step % self.grad_accumulation_factor == 0\n",
        "\n",
        "        outputs = self.compute_forward(batch, sb.Stage.TRAIN)\n",
        "        loss = self.compute_objectives(outputs, batch, sb.Stage.TRAIN)\n",
        "        loss.backward()\n",
        "        if self.check_gradients(loss):\n",
        "            self.optimizer.step()\n",
        "        self.zero_grad()\n",
        "        self.optimizer_step += 1\n",
        "        self.hparams.noam_annealing(self.optimizer)\n",
        "\n",
        "        self.on_fit_batch_end(batch, outputs, loss, should_step)\n",
        "        return loss.detach().cpu()"
      ],
      "metadata": {
        "id": "wUEBBUOQZ4V-"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_hyperparameters = \"\"\"\n",
        "# Setup the directory to host experiment results\n",
        "output_folder: !ref results/transformer/Task_1\n",
        "wer_file: !ref <output_folder>/wer.txt\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n",
        "\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        model: !ref <model>\n",
        "        noam_scheduler: !ref <noam_annealing>\n",
        "        normalizer: !ref <normalize>\n",
        "        counter: !ref <epoch_counter>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DDQEQ8M2MNAi"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = global_hyperparams + task_hyperparameters\n",
        "hparams = load_hyperpyyaml(hyperparams)\n",
        "\n",
        "# Create experiment directory\n",
        "sb.create_experiment_directory(\n",
        "    experiment_directory=hparams[\"output_folder\"],\n",
        "    overrides=None,\n",
        ")\n",
        "\n",
        "# Here we create the datasets objects as well as tokenization and encoding\n",
        "(\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    test_data,\n",
        "    tokenizer\n",
        ") = dataio_prepare(hparams)\n",
        "\n",
        "# We download the pretrained LM from HuggingFace (or elsewhere depending on\n",
        "# the path given in the YAML file). The tokenizer is loaded at the same time.\n",
        "run_on_main(hparams[\"pretrainer\"].collect_files)\n",
        "hparams[\"pretrainer\"].load_collected(device=run_opts[\"device\"])\n",
        "\n",
        "# Trainer initialization\n",
        "asr_brain = BaseASR(\n",
        "    modules=hparams[\"modules\"],\n",
        "    opt_class=hparams[\"Adam\"],\n",
        "    hparams=hparams,\n",
        "    checkpointer=hparams[\"checkpointer\"],\n",
        "    run_opts=run_opts,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# adding objects to trainer:\n",
        "train_dataloader_opts = hparams[\"train_dataloader_opts\"]\n",
        "valid_dataloader_opts = hparams[\"valid_dataloader_opts\"]\n",
        "\n",
        "# Training\n",
        "asr_brain.fit(\n",
        "    asr_brain.hparams.epoch_counter,\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    train_loader_kwargs=train_dataloader_opts,\n",
        "    valid_loader_kwargs=valid_dataloader_opts\n",
        ")\n",
        "\n",
        "# Testing\n",
        "asr_brain.hparams.test_wer_file = asr_brain.hparams.wer_file\n",
        "asr_brain.evaluate(\n",
        "    test_data,\n",
        "    max_key=\"epoch\",\n",
        "    test_loader_kwargs=hparams[\"test_dataloader_opts\"],\n",
        ")"
      ],
      "metadata": {
        "id": "tGonNC7u8hlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b997e3b1-5904-4d83-e03e-63105d3d93e7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/transformer/Task_1\n",
            "speechbrain.pretrained.fetching - Fetch tokenizer.ckpt: Using existing file/symlink in model_checkpoints/tokenizer.ckpt.\n",
            "speechbrain.utils.parameter_transfer - Set local path in self.paths[tokenizer] = model_checkpoints/tokenizer.ckpt\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: tokenizer\n",
            "speechbrain.utils.parameter_transfer - Redirecting (loading from local path): model_checkpoints/tokenizer.ckpt -> model_checkpoints/tokenizer.ckpt\n",
            "speechbrain.core - Info: max_grad_norm arg from hparam file is used\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - 698.9k trainable parameters in BaseASR\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:29<00:00,  6.42it/s, train_loss=537]\n",
            "100%|██████████| 137/137 [00:09<00:00, 14.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 1, lr: 1.26e-04, steps: 190, optimizer: Adam - train loss: 5.37e+02 - valid loss: 2.42e+02, valid CER: 1.00e+02, valid WER: 1.00e+02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-28-15+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 190/190 [00:25<00:00,  7.43it/s, train_loss=433]\n",
            "100%|██████████| 137/137 [00:09<00:00, 14.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 2, lr: 2.53e-04, steps: 380, optimizer: Adam - train loss: 4.33e+02 - valid loss: 2.34e+02, valid CER: 1.00e+02, valid WER: 1.00e+02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-28-51+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.46it/s, train_loss=431]\n",
            "100%|██████████| 137/137 [00:08<00:00, 15.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 3, lr: 3.79e-04, steps: 570, optimizer: Adam - train loss: 4.31e+02 - valid loss: 2.34e+02, valid CER: 1.00e+02, valid WER: 1.00e+02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-29-25+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 190/190 [00:25<00:00,  7.48it/s, train_loss=428]\n",
            "100%|██████████| 137/137 [00:08<00:00, 15.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 4, lr: 5.06e-04, steps: 760, optimizer: Adam - train loss: 4.28e+02 - valid loss: 2.31e+02, valid CER: 1.00e+02, valid WER: 1.00e+02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-29-59+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 190/190 [00:25<00:00,  7.48it/s, train_loss=411]\n",
            "100%|██████████| 137/137 [00:08<00:00, 16.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 5, lr: 6.33e-04, steps: 950, optimizer: Adam - train loss: 4.11e+02 - valid loss: 2.14e+02, valid CER: 94.87, valid WER: 99.79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-30-33+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:26<00:00,  7.29it/s, train_loss=370]\n",
            "100%|██████████| 137/137 [00:11<00:00, 12.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 6, lr: 7.59e-04, steps: 1140, optimizer: Adam - train loss: 3.70e+02 - valid loss: 1.91e+02, valid CER: 75.43, valid WER: 95.31\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-31-10+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:26<00:00,  7.30it/s, train_loss=335]\n",
            "100%|██████████| 137/137 [00:11<00:00, 11.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 7, lr: 8.86e-04, steps: 1330, optimizer: Adam - train loss: 3.35e+02 - valid loss: 1.74e+02, valid CER: 70.41, valid WER: 94.23\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-31-48+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 190/190 [00:25<00:00,  7.49it/s, train_loss=306]\n",
            "100%|██████████| 137/137 [00:12<00:00, 11.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 8, lr: 9.94e-04, steps: 1520, optimizer: Adam - train loss: 3.06e+02 - valid loss: 1.61e+02, valid CER: 65.11, valid WER: 92.03\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-32-26+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 190/190 [00:25<00:00,  7.47it/s, train_loss=283]\n",
            "100%|██████████| 137/137 [00:12<00:00, 10.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 9, lr: 9.37e-04, steps: 1710, optimizer: Adam - train loss: 2.83e+02 - valid loss: 1.51e+02, valid CER: 58.89, valid WER: 89.52\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-33-05+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.44it/s, train_loss=264]\n",
            "100%|██████████| 137/137 [00:13<00:00, 10.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 10, lr: 8.89e-04, steps: 1900, optimizer: Adam - train loss: 2.64e+02 - valid loss: 1.44e+02, valid CER: 56.19, valid WER: 88.15\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-33-44+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:26<00:00,  7.15it/s, train_loss=249]\n",
            "100%|██████████| 137/137 [00:13<00:00, 10.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 11, lr: 8.47e-04, steps: 2090, optimizer: Adam - train loss: 2.49e+02 - valid loss: 1.39e+02, valid CER: 54.63, valid WER: 87.12\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-34-24+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-28-15+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.38it/s, train_loss=237]\n",
            "100%|██████████| 137/137 [00:13<00:00,  9.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 12, lr: 8.11e-04, steps: 2280, optimizer: Adam - train loss: 2.37e+02 - valid loss: 1.34e+02, valid CER: 51.81, valid WER: 85.55\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-35-04+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-28-51+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.35it/s, train_loss=226]\n",
            "100%|██████████| 137/137 [00:13<00:00,  9.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 13, lr: 7.79e-04, steps: 2470, optimizer: Adam - train loss: 2.26e+02 - valid loss: 1.30e+02, valid CER: 49.96, valid WER: 84.99\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-35-44+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-29-25+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.36it/s, train_loss=216]\n",
            "100%|██████████| 137/137 [00:15<00:00,  9.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 14, lr: 7.51e-04, steps: 2660, optimizer: Adam - train loss: 2.16e+02 - valid loss: 1.27e+02, valid CER: 49.22, valid WER: 84.27\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-36-25+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-29-59+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.49it/s, train_loss=209]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 15, lr: 7.26e-04, steps: 2850, optimizer: Adam - train loss: 2.09e+02 - valid loss: 1.24e+02, valid CER: 46.92, valid WER: 83.66\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-37-05+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-30-33+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.46it/s, train_loss=201]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 16, lr: 7.03e-04, steps: 3040, optimizer: Adam - train loss: 2.01e+02 - valid loss: 1.22e+02, valid CER: 45.44, valid WER: 82.63\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-37-45+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-31-10+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.38it/s, train_loss=194]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 17, lr: 6.82e-04, steps: 3230, optimizer: Adam - train loss: 1.94e+02 - valid loss: 1.19e+02, valid CER: 44.77, valid WER: 82.40\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-38-26+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-31-48+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.43it/s, train_loss=188]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 18, lr: 6.62e-04, steps: 3420, optimizer: Adam - train loss: 1.88e+02 - valid loss: 1.18e+02, valid CER: 44.20, valid WER: 82.01\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-39-06+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-32-26+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.43it/s, train_loss=182]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 19, lr: 6.45e-04, steps: 3610, optimizer: Adam - train loss: 1.82e+02 - valid loss: 1.16e+02, valid CER: 43.08, valid WER: 81.22\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-39-47+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-33-05+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.44it/s, train_loss=177]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 20, lr: 6.28e-04, steps: 3800, optimizer: Adam - train loss: 1.77e+02 - valid loss: 1.15e+02, valid CER: 42.19, valid WER: 80.79\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-40-28+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-33-44+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.49it/s, train_loss=172]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 21, lr: 6.13e-04, steps: 3990, optimizer: Adam - train loss: 1.72e+02 - valid loss: 1.14e+02, valid CER: 42.20, valid WER: 80.49\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-41-08+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-34-24+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:26<00:00,  7.22it/s, train_loss=168]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 22, lr: 5.99e-04, steps: 4180, optimizer: Adam - train loss: 1.68e+02 - valid loss: 1.13e+02, valid CER: 41.35, valid WER: 80.42\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-41-50+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-35-04+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.48it/s, train_loss=164]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 23, lr: 5.86e-04, steps: 4370, optimizer: Adam - train loss: 1.64e+02 - valid loss: 1.13e+02, valid CER: 40.99, valid WER: 80.15\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-42-31+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-35-44+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.44it/s, train_loss=160]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 24, lr: 5.74e-04, steps: 4560, optimizer: Adam - train loss: 1.60e+02 - valid loss: 1.11e+02, valid CER: 40.59, valid WER: 79.61\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-43-12+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-36-25+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.38it/s, train_loss=156]\n",
            "100%|██████████| 137/137 [00:15<00:00,  9.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 25, lr: 5.62e-04, steps: 4750, optimizer: Adam - train loss: 1.56e+02 - valid loss: 1.11e+02, valid CER: 40.12, valid WER: 79.57\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-43-53+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-37-05+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.45it/s, train_loss=152]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 26, lr: 5.51e-04, steps: 4940, optimizer: Adam - train loss: 1.52e+02 - valid loss: 1.10e+02, valid CER: 39.85, valid WER: 78.91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-44-35+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-37-45+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.50it/s, train_loss=150]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 27, lr: 5.41e-04, steps: 5130, optimizer: Adam - train loss: 1.50e+02 - valid loss: 1.10e+02, valid CER: 39.33, valid WER: 78.13\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-45-16+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-38-26+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.50it/s, train_loss=146]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 28, lr: 5.31e-04, steps: 5320, optimizer: Adam - train loss: 1.46e+02 - valid loss: 1.10e+02, valid CER: 39.06, valid WER: 77.77\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-45-56+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-39-06+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:26<00:00,  7.18it/s, train_loss=143]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 29, lr: 5.22e-04, steps: 5510, optimizer: Adam - train loss: 1.43e+02 - valid loss: 1.09e+02, valid CER: 38.79, valid WER: 77.54\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-46-38+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-39-47+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.47it/s, train_loss=140]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 30, lr: 5.13e-04, steps: 5700, optimizer: Adam - train loss: 1.40e+02 - valid loss: 1.08e+02, valid CER: 38.28, valid WER: 77.42\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-47-19+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_1/save/CKPT+2024-02-17+14-40-28+00\n",
            "speechbrain.utils.checkpoints - Loading a checkpoint from results/transformer/Task_1/save/CKPT+2024-02-17+14-47-19+00\n",
            "Loaded the average\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 328/328 [00:43<00:00,  7.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - Epoch loaded: 30 - test loss: 1.22e+02, test CER: 39.75, test WER: 78.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "122.01812960461884"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part II(A): CTC is all you need\n",
        "In this section, you will train a **6-layer Conformer** encoder with both  `CTC` and `inter-CTC` losses.\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "wHIRKDrPPRGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ASR_2A(BaseASR):\n",
        "    def __init__(\n",
        "        self, *args, **kwargs\n",
        "    ):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.inter_ctc_weight = self.hparams.interctc_weight\n",
        "        self.intermediate_layers = [int(layer) for layer in self.hparams.intermediate_layers.split(',')]\n",
        "\n",
        "        # Variable to hold intermediate logits for interCTC loss calculation\n",
        "        self.inter_logits = []\n",
        "\n",
        "        # TODO: Define a helper function get_intermediate_output for the forward hook\n",
        "        def get_intermediate_output(module, input, output):\n",
        "            # TODO: Complete this function\n",
        "            self.inter_logits.append(output)\n",
        "\n",
        "\n",
        "        # TODO: Register hooks for all the intermediate encoder layers of interest.\n",
        "        # TODO: Refer to register_forward_hook (https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_forward_hook.html)\n",
        "        # TODO: Save all the hooks in a list self.hooks that you can remove later from the module\n",
        "        self.hooks = [self.modules.Transformer.encoder.layers[i-1].register_forward_hook(get_intermediate_output) for i in self.intermediate_layers] #i-1 since 1 indexed\n",
        "\n",
        "\n",
        "\n",
        "    def compute_forward(self, batch, stage):\n",
        "        \"\"\"Performs a forward pass through the encoder\"\"\"\n",
        "        batch = batch.to(self.device)\n",
        "        wavs, wav_lens = batch.sig\n",
        "        tokens_bos, _ = batch.tokens_bos\n",
        "\n",
        "        # compute features\n",
        "        feats = self.hparams.compute_features(wavs)\n",
        "        current_epoch = self.hparams.epoch_counter.current\n",
        "        feats = self.modules.normalize(feats, wav_lens, epoch=current_epoch)\n",
        "\n",
        "        # forward modules\n",
        "        src = self.modules.CNN(feats)\n",
        "\n",
        "        assert len(self.inter_logits) == 0, \"self.inter_logits should be empty as we haven't done a forward pass yet\"\n",
        "        enc_out, _ = self.modules.Transformer(\n",
        "            src, tokens_bos, wav_lens, pad_idx=self.hparams.pad_index,\n",
        "        )\n",
        "\n",
        "        # Compute final layer logit\n",
        "        logits = self.modules.ctc_lin(enc_out)\n",
        "        p_ctc = self.hparams.log_softmax(logits)\n",
        "\n",
        "        # TODO: Append all the intermediate layer logits to the following list: inter_p_ctc\n",
        "        # TODO: Go through all the layers in intermediate_layers. Note that the comma-separated list in intermediate_layers is 1-indexed.\n",
        "        # TODO: Complete code below to populate inter_p_ctc\n",
        "\n",
        "        inter_p_ctc = [self.hparams.log_softmax(self.modules.ctc_lin(temp_logits[0])) for temp_logits in self.inter_logits]\n",
        "\n",
        "        # Flush the logits saved during last forward pass.\n",
        "        self.inter_logits = []\n",
        "\n",
        "        # Compute outputs\n",
        "        hyps = None\n",
        "        if stage == sb.Stage.TRAIN:\n",
        "            assert len(inter_p_ctc) != 0 , \"inter_p_ctc should NOT be empty as forward pass is already done\"\n",
        "            hyps = None\n",
        "        else:\n",
        "            hyps = sb.decoders.ctc_greedy_decode(\n",
        "                p_ctc, wav_lens, blank_id=self.hparams.blank_index\n",
        "            )\n",
        "\n",
        "        return p_ctc, inter_p_ctc, wav_lens, hyps\n",
        "\n",
        "    def on_evaluate_start(self, max_key=None, min_key=None):\n",
        "        \"\"\"Performs sanity operations before inferencing on the test set.\"\"\"\n",
        "        if self.checkpointer is not None:\n",
        "            self.checkpointer.recover_if_possible(\n",
        "                max_key=max_key,\n",
        "                min_key=min_key,\n",
        "                device=torch.device(self.device),\n",
        "            )\n",
        "\n",
        "        # Deregister hooks here as they are not needed during evaluation\n",
        "        for hook in self.hooks:\n",
        "            hook.remove()\n",
        "\n",
        "    def compute_objectives(self, predictions, batch, stage):\n",
        "        \"\"\"Computes the CTC + inter-CTC loss given predictions and targets.\"\"\"\n",
        "\n",
        "        (p_ctc, inter_p_ctc, wav_lens, hyps,) = predictions\n",
        "\n",
        "        ids = batch.id\n",
        "        tokens_eos, tokens_eos_lens = batch.tokens_eos\n",
        "        tokens, tokens_lens = batch.tokens\n",
        "\n",
        "        # TODO: Compute inter-CTC loss\n",
        "        loss_inter_ctc = sum(self.hparams.ctc_cost(temp_inter_p_ctc, tokens, wav_lens, tokens_lens) for temp_inter_p_ctc in inter_p_ctc)\n",
        "        # TODO: Write code to appropriately accumulate the inter-CTC loss in loss_inter_ctc\n",
        "        # TODO: using the softmax probabilities saved for each intermediate layer in inter_p_ctc\n",
        "\n",
        "        # Compute final layer CTC loss\n",
        "        loss_ctc = self.hparams.ctc_cost(p_ctc, tokens, wav_lens, tokens_lens)\n",
        "\n",
        "        # Compute final loss as a weighted combination of inter-CTC and CTC\n",
        "        loss = self.inter_ctc_weight * loss_inter_ctc + (1 - self.inter_ctc_weight) * loss_ctc\n",
        "\n",
        "        if stage != sb.Stage.TRAIN:\n",
        "            # Decode token terms to words\n",
        "            predicted_words = [\n",
        "                    self.tokenizer.decode_ids(utt_seq).split(\" \") for utt_seq in hyps\n",
        "                ]\n",
        "            target_words = [wrd.split(\" \") for wrd in batch.wrd]\n",
        "            self.wer_metric.append(ids, predicted_words, target_words)\n",
        "            self.cer_metric.append(ids, predicted_words, target_words)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "SdoAx39-pSAw"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_hyperparameters = \"\"\"\n",
        "\n",
        "# Setup the directory to host experiment results\n",
        "output_folder: !ref results/transformer/Part_2A\n",
        "wer_file: !ref <output_folder>/wer.txt\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "\n",
        "interctc_weight: 0.3\n",
        "intermediate_layers: '2,4'\n",
        "\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n",
        "\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        model: !ref <model>\n",
        "        noam_scheduler: !ref <noam_annealing>\n",
        "        normalizer: !ref <normalize>\n",
        "        counter: !ref <epoch_counter>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aoIb-4TdnyC4"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = global_hyperparams + task_hyperparameters\n",
        "hparams = load_hyperpyyaml(hyperparams)\n",
        "\n",
        "# Create experiment directory\n",
        "sb.create_experiment_directory(\n",
        "    experiment_directory=hparams[\"output_folder\"],\n",
        "    overrides=None,\n",
        ")\n",
        "\n",
        "# We download the pretrained LM from HuggingFace (or elsewhere depending on\n",
        "# the path given in the YAML file). The tokenizer is loaded at the same time.\n",
        "run_on_main(hparams[\"pretrainer\"].collect_files)\n",
        "hparams[\"pretrainer\"].load_collected(device=run_opts[\"device\"])\n",
        "\n",
        "# Trainer initialization\n",
        "asr_brain = ASR_2A(\n",
        "    modules=hparams[\"modules\"],\n",
        "    opt_class=hparams[\"Adam\"],\n",
        "    hparams=hparams,\n",
        "    checkpointer=hparams[\"checkpointer\"],\n",
        "    run_opts=run_opts,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# adding objects to trainer:\n",
        "train_dataloader_opts = hparams[\"train_dataloader_opts\"]\n",
        "valid_dataloader_opts = hparams[\"valid_dataloader_opts\"]\n",
        "\n",
        "# Training\n",
        "asr_brain.fit(\n",
        "    asr_brain.hparams.epoch_counter,\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    train_loader_kwargs=train_dataloader_opts,\n",
        "    valid_loader_kwargs=valid_dataloader_opts\n",
        ")\n",
        "\n",
        "# Testing\n",
        "\n",
        "asr_brain.hparams.test_wer_file = asr_brain.hparams.wer_file\n",
        "asr_brain.evaluate(\n",
        "    test_data,\n",
        "    max_key=\"ACC\",\n",
        "    test_loader_kwargs=hparams[\"test_dataloader_opts\"],\n",
        ")"
      ],
      "metadata": {
        "id": "AX-kl1dKMx-Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56c8da19-5e6f-4b9e-ed09-9172a778b271"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/transformer/Part_2A\n",
            "speechbrain.pretrained.fetching - Fetch tokenizer.ckpt: Using existing file/symlink in model_checkpoints/tokenizer.ckpt.\n",
            "speechbrain.utils.parameter_transfer - Set local path in self.paths[tokenizer] = model_checkpoints/tokenizer.ckpt\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: tokenizer\n",
            "speechbrain.utils.parameter_transfer - Redirecting (loading from local path): model_checkpoints/tokenizer.ckpt -> model_checkpoints/tokenizer.ckpt\n",
            "speechbrain.core - Info: max_grad_norm arg from hparam file is used\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - 698.9k trainable parameters in ASR_2A\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/190 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 56, 64])\n",
            "torch.Size([8, 4, 56, 56])\n",
            "##########\n",
            "torch.Size([8, 56, 64])\n",
            "torch.Size([8, 4, 56, 56])\n",
            "##########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 3/190 [00:00<00:27,  6.70it/s, train_loss=265]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 63, 64])\n",
            "torch.Size([8, 4, 63, 63])\n",
            "##########\n",
            "torch.Size([8, 63, 64])\n",
            "torch.Size([8, 4, 63, 63])\n",
            "##########\n",
            "torch.Size([8, 70, 64])\n",
            "torch.Size([8, 4, 70, 70])\n",
            "##########\n",
            "torch.Size([8, 70, 64])\n",
            "torch.Size([8, 4, 70, 70])\n",
            "##########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 4/190 [00:00<00:36,  5.14it/s, train_loss=272]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 74, 64])\n",
            "torch.Size([8, 4, 74, 74])\n",
            "##########\n",
            "torch.Size([8, 74, 64])\n",
            "torch.Size([8, 4, 74, 74])\n",
            "##########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 5/190 [00:00<00:33,  5.57it/s, train_loss=279]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 77, 64])\n",
            "torch.Size([8, 4, 77, 77])\n",
            "##########\n",
            "torch.Size([8, 77, 64])\n",
            "torch.Size([8, 4, 77, 77])\n",
            "##########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 6/190 [00:01<00:36,  5.09it/s, train_loss=288]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 82, 64])\n",
            "torch.Size([8, 4, 82, 82])\n",
            "##########\n",
            "torch.Size([8, 82, 64])\n",
            "torch.Size([8, 4, 82, 82])\n",
            "##########\n",
            "torch.Size([8, 86, 64])\n",
            "torch.Size([8, 4, 86, 86])\n",
            "##########\n",
            "torch.Size([8, 86, 64])\n",
            "torch.Size([8, 4, 86, 86])\n",
            "##########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 8/190 [00:01<00:34,  5.31it/s, train_loss=304]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 91, 64])\n",
            "torch.Size([8, 4, 91, 91])\n",
            "##########\n",
            "torch.Size([8, 91, 64])\n",
            "torch.Size([8, 4, 91, 91])\n",
            "##########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 9/190 [00:01<00:37,  4.79it/s, train_loss=323]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 97, 64])\n",
            "torch.Size([8, 4, 97, 97])\n",
            "##########\n",
            "torch.Size([8, 97, 64])\n",
            "torch.Size([8, 4, 97, 97])\n",
            "##########\n",
            "torch.Size([8, 106, 64])\n",
            "torch.Size([8, 4, 106, 106])\n",
            "##########\n",
            "torch.Size([8, 106, 64])\n",
            "torch.Size([8, 4, 106, 106])\n",
            "##########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 11/190 [00:01<00:27,  6.57it/s, train_loss=343]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 109, 64])\n",
            "torch.Size([8, 4, 109, 109])\n",
            "##########\n",
            "torch.Size([8, 109, 64])\n",
            "torch.Size([8, 4, 109, 109])\n",
            "##########\n",
            "torch.Size([8, 116, 64])\n",
            "torch.Size([8, 4, 116, 116])\n",
            "##########\n",
            "torch.Size([8, 116, 64])\n",
            "torch.Size([8, 4, 116, 116])\n",
            "##########\n",
            "torch.Size([8, 120, 64])\n",
            "torch.Size([8, 4, 120, 120])\n",
            "##########\n",
            "torch.Size([8, 120, 64])\n",
            "torch.Size([8, 4, 120, 120])\n",
            "##########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 15/190 [00:02<00:19,  8.95it/s, train_loss=372]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 123, 64])\n",
            "torch.Size([8, 4, 123, 123])\n",
            "##########\n",
            "torch.Size([8, 123, 64])\n",
            "torch.Size([8, 4, 123, 123])\n",
            "##########\n",
            "torch.Size([8, 131, 64])\n",
            "torch.Size([8, 4, 131, 131])\n",
            "##########\n",
            "torch.Size([8, 131, 64])\n",
            "torch.Size([8, 4, 131, 131])\n",
            "##########\n",
            "torch.Size([8, 134, 64])\n",
            "torch.Size([8, 4, 134, 134])\n",
            "##########\n",
            "torch.Size([8, 134, 64])\n",
            "torch.Size([8, 4, 134, 134])\n",
            "##########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 17/190 [00:02<00:17,  9.72it/s, train_loss=402]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 144, 64])\n",
            "torch.Size([8, 4, 144, 144])\n",
            "##########\n",
            "torch.Size([8, 144, 64])\n",
            "torch.Size([8, 4, 144, 144])\n",
            "##########\n",
            "torch.Size([8, 148, 64])\n",
            "torch.Size([8, 4, 148, 148])\n",
            "##########\n",
            "torch.Size([8, 148, 64])\n",
            "torch.Size([8, 4, 148, 148])\n",
            "##########\n",
            "torch.Size([8, 158, 64])\n",
            "torch.Size([8, 4, 158, 158])\n",
            "##########\n",
            "torch.Size([8, 158, 64])\n",
            "torch.Size([8, 4, 158, 158])\n",
            "##########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 21/190 [00:02<00:16, 10.44it/s, train_loss=434]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 164, 64])\n",
            "torch.Size([8, 4, 164, 164])\n",
            "##########\n",
            "torch.Size([8, 164, 64])\n",
            "torch.Size([8, 4, 164, 164])\n",
            "##########\n",
            "torch.Size([8, 169, 64])\n",
            "torch.Size([8, 4, 169, 169])\n",
            "##########\n",
            "torch.Size([8, 169, 64])\n",
            "torch.Size([8, 4, 169, 169])\n",
            "##########\n",
            "torch.Size([8, 176, 64])\n",
            "torch.Size([8, 4, 176, 176])\n",
            "##########\n",
            "torch.Size([8, 176, 64])\n",
            "torch.Size([8, 4, 176, 176])\n",
            "##########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 23/190 [00:03<00:16, 10.40it/s, train_loss=467]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 182, 64])\n",
            "torch.Size([8, 4, 182, 182])\n",
            "##########\n",
            "torch.Size([8, 182, 64])\n",
            "torch.Size([8, 4, 182, 182])\n",
            "##########\n",
            "torch.Size([8, 189, 64])\n",
            "torch.Size([8, 4, 189, 189])\n",
            "##########\n",
            "torch.Size([8, 189, 64])\n",
            "torch.Size([8, 4, 189, 189])\n",
            "##########\n",
            "torch.Size([8, 192, 64])\n",
            "torch.Size([8, 4, 192, 192])\n",
            "##########\n",
            "torch.Size([8, 192, 64])\n",
            "torch.Size([8, 4, 192, 192])\n",
            "##########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 27/190 [00:03<00:15, 10.50it/s, train_loss=498]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 198, 64])\n",
            "torch.Size([8, 4, 198, 198])\n",
            "##########\n",
            "torch.Size([8, 198, 64])\n",
            "torch.Size([8, 4, 198, 198])\n",
            "##########\n",
            "torch.Size([8, 204, 64])\n",
            "torch.Size([8, 4, 204, 204])\n",
            "##########\n",
            "torch.Size([8, 204, 64])\n",
            "torch.Size([8, 4, 204, 204])\n",
            "##########\n",
            "torch.Size([8, 211, 64])\n",
            "torch.Size([8, 4, 211, 211])\n",
            "##########\n",
            "torch.Size([8, 211, 64])\n",
            "torch.Size([8, 4, 211, 211])\n",
            "##########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 29/190 [00:03<00:15, 10.41it/s, train_loss=527]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 217, 64])\n",
            "torch.Size([8, 4, 217, 217])\n",
            "##########\n",
            "torch.Size([8, 217, 64])\n",
            "torch.Size([8, 4, 217, 217])\n",
            "##########\n",
            "torch.Size([8, 219, 64])\n",
            "torch.Size([8, 4, 219, 219])\n",
            "##########\n",
            "torch.Size([8, 219, 64])\n",
            "torch.Size([8, 4, 219, 219])\n",
            "##########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▋        | 31/190 [00:03<00:15, 10.11it/s, train_loss=545]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 224, 64])\n",
            "torch.Size([8, 4, 224, 224])\n",
            "##########\n",
            "torch.Size([8, 224, 64])\n",
            "torch.Size([8, 4, 224, 224])\n",
            "##########\n",
            "torch.Size([8, 227, 64])\n",
            "torch.Size([8, 4, 227, 227])\n",
            "##########\n",
            "torch.Size([8, 227, 64])\n",
            "torch.Size([8, 4, 227, 227])\n",
            "##########\n",
            "torch.Size([8, 231, 64])\n",
            "torch.Size([8, 4, 231, 231])\n",
            "##########\n",
            "torch.Size([8, 231, 64])\n",
            "torch.Size([8, 4, 231, 231])\n",
            "##########\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 33/190 [00:03<00:18,  8.30it/s, train_loss=554]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-9bb3c701ef9a>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m asr_brain.fit(\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0masr_brain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_counter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/speechbrain/speechbrain/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epoch_counter, train_set, valid_set, progressbar, train_loader_kwargs, valid_loader_kwargs)\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \u001b[0;31m# Iterate epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_counter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/speechbrain/speechbrain/core.py\u001b[0m in \u001b[0;36m_fit_train\u001b[0;34m(self, train_set, epoch, enable)\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0mcolour\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm_barcolor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         ) as t:\n\u001b[0;32m-> 1187\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_limit_exceeded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train iteration limit exceeded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/speechbrain/speechbrain/dataio/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mdata_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mdata_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdata_point\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_dynamic_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/speechbrain/speechbrain/utils/data_pipeline.py\u001b[0m in \u001b[0;36mcompute_outputs\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec_order\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_specific\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/speechbrain/speechbrain/utils/data_pipeline.py\u001b[0m in \u001b[0;36m_compute\u001b[0;34m(self, data, order, output_mapping)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;31m# This needs to be called BEFORE the dynamic item is called.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mprovided_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_provides\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Call the DynamicItem to produce output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;31m# If there is just one output value, wrap in a list so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;31m# it can be zipped as well:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/speechbrain/speechbrain/utils/data_pipeline.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# The next methods are more about supporting GeneratorDynamicItems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-e7aa071665c6>\u001b[0m in \u001b[0;36maudio_pipeline\u001b[0;34m(wav)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maudio_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m\"\"\"Load the audio signal. This is done on the CPU in the `collate_fn`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/speechbrain/speechbrain/dataio/dataio.py\u001b[0m in \u001b[0;36mread_audio\u001b[0;34m(waveforms_obj)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \"\"\"\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveforms_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveforms_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaveforms_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchaudio/_backend/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[1;32m    202\u001b[0m         \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchaudio/_backend/ffmpeg.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m    332\u001b[0m             )\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchaudio/_backend/ffmpeg.py\u001b[0m in \u001b[0;36mload_audio\u001b[0;34m(src, frame_offset, num_frames, convert, channels_first, format)\u001b[0m\n\u001b[1;32m     98\u001b[0m ) -> Tuple[torch.Tensor, int]:\n\u001b[1;32m     99\u001b[0m     \u001b[0mfilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_load_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2.2: The PowerConv Module\n",
        "In this section, we will update the Conformer encoder by replacing Convolution with **PowerConv**. Rest of the architecture remains the same. Note this will be added on top of inter-CTC."
      ],
      "metadata": {
        "id": "06q84-WOPblt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task_hyperparameters = \"\"\"\n",
        "\n",
        "# Setup the directory to host experiment results\n",
        "output_folder: !ref results/transformer/Task_2B\n",
        "wer_file: !ref <output_folder>/wer.txt\n",
        "save_folder: !ref <output_folder>/save\n",
        "train_log: !ref <output_folder>/train_log.txt\n",
        "\n",
        "interctc_weight: 0.3\n",
        "intermediate_layers: '2,4'\n",
        "\n",
        "train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger\n",
        "    save_file: !ref <train_log>\n",
        "\n",
        "checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer\n",
        "    checkpoints_dir: !ref <save_folder>\n",
        "    recoverables:\n",
        "        model: !ref <model>\n",
        "        noam_scheduler: !ref <noam_annealing>\n",
        "        normalizer: !ref <normalize>\n",
        "        counter: !ref <epoch_counter>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BwQRTzBE3Qga"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import speechbrain as sb\n",
        "\n",
        "from speechbrain.nnet.attention import (\n",
        "    RelPosMHAXL,\n",
        "    MultiheadAttention,\n",
        "    PositionalwiseFeedForward,\n",
        ")\n",
        "from speechbrain.nnet.normalization import LayerNorm\n",
        "from speechbrain.nnet.activations import Swish\n",
        "from speechbrain.nnet.CNN import Conv1d\n",
        "\n",
        "class PowerConv(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        kernel_size=31,\n",
        "        dropout=0.0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # We upsample our input by a factor of 2 to\n",
        "        input_size = input_size*2\n",
        "        self.input_size = input_size\n",
        "\n",
        "        n_channels = input_size // 2  # split input channels\n",
        "\n",
        "        # TODO: First projection feedforward layer to upsample the input\n",
        "        self.channel_proj1 = torch.nn.Linear(n_channels,input_size)\n",
        "        self.norm1 = LayerNorm(n_channels)\n",
        "        self.norm2 = LayerNorm(n_channels)\n",
        "        self.conv = Conv1d(in_channels=n_channels, out_channels=n_channels,groups=n_channels, kernel_size=kernel_size)\n",
        "        ### TODO: Use the groups parameter in the Conv1D class and set it to n_channels\n",
        "        ### TODO: Note that this conv operator does not change the feature dimensionality.\n",
        "        ### TODO: Use the appropriate value for the padding parameter in the Conv1D class to keep the feature dimensionality unaltered.\n",
        "\n",
        "        # TODO: Second projection feedforward layer\n",
        "        self.channel_proj2 = torch.nn.Linear(n_channels,n_channels)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "\n",
        "        # Initialize convolution with ones.\n",
        "        torch.nn.init.ones_(self.conv.conv.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "            Shape of input x: (B, T, D)\n",
        "            Return output of shape: (B, T, D)\n",
        "        \"\"\"\n",
        "        # TODO: Implement the PowerConv module as described in the assignment pdf\n",
        "        x = self.norm1(x)\n",
        "        V = self.channel_proj1(x)\n",
        "        v1,v2 = V[...,:self.input_size//2],V[...,self.input_size//2:]\n",
        "        v2 = self.norm2(v2)\n",
        "        v2 = self.conv(v2)\n",
        "        z = v1*v2\n",
        "        x = self.dropout(z)\n",
        "        x = self.channel_proj2(x)\n",
        "        return x\n",
        "\n",
        "class CustomConformerEncoderLayer(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model,\n",
        "        d_ffn,\n",
        "        nhead,\n",
        "        kernel_size=31,\n",
        "        kdim=None,\n",
        "        vdim=None,\n",
        "        activation=Swish,\n",
        "        bias=True,\n",
        "        dropout=0.0,\n",
        "        causal=False,\n",
        "        attention_type=\"RelPosMHAXL\",\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Self attention block\n",
        "        if attention_type == \"regularMHA\":\n",
        "            self.mha_layer = MultiheadAttention(\n",
        "                nhead=nhead,\n",
        "                d_model=d_model,\n",
        "                dropout=dropout,\n",
        "                kdim=kdim,\n",
        "                vdim=vdim,\n",
        "            )\n",
        "        elif attention_type == \"RelPosMHAXL\":\n",
        "            # transformerXL style positional encoding\n",
        "            self.mha_layer = RelPosMHAXL(\n",
        "                num_heads=nhead,\n",
        "                embed_dim=d_model,\n",
        "                dropout=dropout,\n",
        "                mask_pos_future=causal,\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(\"Unknown attention type\")\n",
        "\n",
        "        # Create instance of our custom convolution block\n",
        "        self.convolution_module = PowerConv(\n",
        "            d_model, kernel_size, dropout\n",
        "        )\n",
        "\n",
        "        # Feed forward macaron block\n",
        "        self.ffn_module1 = torch.nn.Sequential(\n",
        "            torch.nn.LayerNorm(d_model),\n",
        "            PositionalwiseFeedForward(\n",
        "                d_ffn=d_ffn,\n",
        "                input_size=d_model,\n",
        "                dropout=dropout,\n",
        "                activation=activation,\n",
        "            ),\n",
        "            torch.nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        # Feed forward block\n",
        "        self.ffn_module2 = torch.nn.Sequential(\n",
        "            torch.nn.LayerNorm(d_model),\n",
        "            PositionalwiseFeedForward(\n",
        "                d_ffn=d_ffn,\n",
        "                input_size=d_model,\n",
        "                dropout=dropout,\n",
        "                activation=activation,\n",
        "            ),\n",
        "            torch.nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        self.norm1 = LayerNorm(d_model)\n",
        "        self.norm2 = LayerNorm(d_model)\n",
        "        self.drop = torch.nn.Dropout(dropout)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x,\n",
        "        src_mask = None,\n",
        "        src_key_padding_mask = None,\n",
        "        pos_embs = None,\n",
        "    ):\n",
        "        conv_mask = None\n",
        "        if src_key_padding_mask is not None:\n",
        "            conv_mask = src_key_padding_mask.unsqueeze(-1)\n",
        "\n",
        "        # ffn module\n",
        "        x = x + 0.5 * self.ffn_module1(x)\n",
        "\n",
        "        # muti-head attention module\n",
        "        skip = x\n",
        "        x = self.norm1(x)\n",
        "        x, self_attn = self.mha_layer(\n",
        "            x,\n",
        "            x,\n",
        "            x,\n",
        "            attn_mask=src_mask,\n",
        "            key_padding_mask=src_key_padding_mask,\n",
        "            pos_embs=pos_embs,\n",
        "        )\n",
        "        x = x + skip\n",
        "\n",
        "        # convolution module\n",
        "        x = x + self.convolution_module(x)\n",
        "\n",
        "        # ffn module\n",
        "        x = self.norm2(x + 0.5 * self.ffn_module2(x))\n",
        "\n",
        "        return x, self_attn\n",
        "\n",
        "\n",
        "class CustomConformerEncoder(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        d_model,\n",
        "        d_ffn,\n",
        "        nhead,\n",
        "        kernel_size=31,\n",
        "        kdim=None,\n",
        "        vdim=None,\n",
        "        activation=Swish,\n",
        "        bias=True,\n",
        "        dropout=0.0,\n",
        "        causal=False,\n",
        "        attention_type=\"RelPosMHAXL\",\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Create layers using our custom encoder layer that utilizes PowerConv\n",
        "        self.layers = torch.nn.ModuleList(\n",
        "            [\n",
        "                CustomConformerEncoderLayer(\n",
        "                    d_ffn=d_ffn,\n",
        "                    nhead=nhead,\n",
        "                    d_model=d_model,\n",
        "                    kdim=kdim,\n",
        "                    vdim=vdim,\n",
        "                    dropout=dropout,\n",
        "                    activation=activation,\n",
        "                    kernel_size=kernel_size,\n",
        "                    bias=bias,\n",
        "                    causal=causal,\n",
        "                    attention_type=attention_type,\n",
        "                )\n",
        "                for i in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "        self.norm = LayerNorm(d_model, eps=1e-6)\n",
        "        self.attention_type = attention_type\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        src,\n",
        "        src_mask = None,\n",
        "        src_key_padding_mask = None,\n",
        "        pos_embs = None,\n",
        "    ):\n",
        "\n",
        "        if self.attention_type == \"RelPosMHAXL\":\n",
        "            if pos_embs is None:\n",
        "                raise ValueError(\n",
        "                    \"The chosen attention type for the Conformer is RelPosMHAXL. For this attention type, the positional embeddings are mandatory\"\n",
        "                )\n",
        "\n",
        "        output = src\n",
        "        attention_lst = []\n",
        "        # Loop through the encoder layers\n",
        "        for enc_layer in self.layers:\n",
        "            output, attention = enc_layer(\n",
        "                output,\n",
        "                src_mask=src_mask,\n",
        "                src_key_padding_mask=src_key_padding_mask,\n",
        "                pos_embs=pos_embs,\n",
        "            )\n",
        "            attention_lst.append(attention)\n",
        "        output = self.norm(output)\n",
        "\n",
        "        return output, attention_lst"
      ],
      "metadata": {
        "id": "1gneZWFH7TmC"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ASR_2B(ASR_2A):\n",
        "    def __init__(\n",
        "        self, device=\"cpu\", *args, **kwargs\n",
        "    ):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        # Remove the old hooks as they are not useful\n",
        "        for hook in self.hooks:\n",
        "            hook.remove()\n",
        "\n",
        "        # Instantiate our custom encoder that uses PowerConv\n",
        "        encoder = CustomConformerEncoder(\n",
        "            nhead=self.hparams.nhead,\n",
        "            num_layers=self.hparams.num_encoder_layers,\n",
        "            d_ffn=self.hparams.d_ffn,\n",
        "            d_model=self.hparams.d_model,\n",
        "            dropout=self.hparams.transformer_dropout,\n",
        "            activation=self.hparams.activation,\n",
        "            attention_type=self.hparams.attention_type,\n",
        "        ).to(device)\n",
        "\n",
        "        # Replace the standard encoder with our encoder\n",
        "        self.modules.Transformer.encoder = encoder\n",
        "\n",
        "        self.inter_logits = []\n",
        "        def get_intermediate_output(module, input, output):\n",
        "          self.inter_logits.append(output)\n",
        "\n",
        "        self.hooks = [self.modules.Transformer.encoder.layers[i-1].register_forward_hook(get_intermediate_output) for i in self.intermediate_layers] #i-1 since 1 indexed\n",
        "        # TODO: Copy this code from your implemention in Part II(A) within the __init__ function of ASR_2A that populates self.hooks"
      ],
      "metadata": {
        "id": "3wgsf3f27VuR"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = global_hyperparams + task_hyperparameters\n",
        "hparams = load_hyperpyyaml(hyperparams)\n",
        "\n",
        "# Create experiment directory\n",
        "sb.create_experiment_directory(\n",
        "    experiment_directory=hparams[\"output_folder\"],\n",
        "    overrides=None,\n",
        ")\n",
        "\n",
        "# We download the pretrained LM from HuggingFace (or elsewhere depending on\n",
        "# the path given in the YAML file). The tokenizer is loaded at the same time.\n",
        "run_on_main(hparams[\"pretrainer\"].collect_files)\n",
        "hparams[\"pretrainer\"].load_collected(device=run_opts[\"device\"])\n",
        "\n",
        "# Trainer initialization\n",
        "asr_brain = ASR_2B(\n",
        "    modules=hparams[\"modules\"],\n",
        "    opt_class=hparams[\"Adam\"],\n",
        "    hparams=hparams,\n",
        "    checkpointer=hparams[\"checkpointer\"],\n",
        "    run_opts=run_opts,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# adding objects to trainer:\n",
        "train_dataloader_opts = hparams[\"train_dataloader_opts\"]\n",
        "valid_dataloader_opts = hparams[\"valid_dataloader_opts\"]\n",
        "\n",
        "# Training\n",
        "asr_brain.fit(\n",
        "    asr_brain.hparams.epoch_counter,\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    train_loader_kwargs=train_dataloader_opts,\n",
        "    valid_loader_kwargs=valid_dataloader_opts\n",
        ")\n",
        "\n",
        "# Testing\n",
        "\n",
        "asr_brain.hparams.test_wer_file = asr_brain.hparams.wer_file\n",
        "asr_brain.evaluate(\n",
        "    test_data,\n",
        "    max_key=\"ACC\",\n",
        "    test_loader_kwargs=hparams[\"test_dataloader_opts\"],\n",
        ")"
      ],
      "metadata": {
        "id": "s1pcomwa-zwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e8f004-c795-4cdc-81f4-53c02470ba96"
      },
      "execution_count": 77,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "speechbrain.core - Beginning experiment!\n",
            "speechbrain.core - Experiment folder: results/transformer/Task_2B\n",
            "speechbrain.pretrained.fetching - Fetch tokenizer.ckpt: Using existing file/symlink in model_checkpoints/tokenizer.ckpt.\n",
            "speechbrain.utils.parameter_transfer - Set local path in self.paths[tokenizer] = model_checkpoints/tokenizer.ckpt\n",
            "speechbrain.utils.parameter_transfer - Loading pretrained files for: tokenizer\n",
            "speechbrain.utils.parameter_transfer - Redirecting (loading from local path): model_checkpoints/tokenizer.ckpt -> model_checkpoints/tokenizer.ckpt\n",
            "speechbrain.core - Info: max_grad_norm arg from hparam file is used\n",
            "speechbrain.core - Info: ckpt_interval_minutes arg from hparam file is used\n",
            "speechbrain.core - 698.9k trainable parameters in ASR_2B\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n",
            "speechbrain.utils.epoch_loop - Going into epoch 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.41it/s, train_loss=742]\n",
            "100%|██████████| 137/137 [00:09<00:00, 14.65it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "speechbrain.utils.train_logger - epoch: 1, lr: 1.26e-04, steps: 190, optimizer: Adam - train loss: 7.42e+02 - valid loss: 3.15e+02, valid CER: 1.00e+02, valid WER: 1.00e+02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-16-43+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.35it/s, train_loss=564]\n",
            "100%|██████████| 137/137 [00:08<00:00, 15.95it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "speechbrain.utils.train_logger - epoch: 2, lr: 2.53e-04, steps: 380, optimizer: Adam - train loss: 5.64e+02 - valid loss: 3.05e+02, valid CER: 1.00e+02, valid WER: 1.00e+02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-17-17+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.53it/s, train_loss=561]\n",
            "100%|██████████| 137/137 [00:08<00:00, 16.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 3, lr: 3.79e-04, steps: 570, optimizer: Adam - train loss: 5.61e+02 - valid loss: 3.04e+02, valid CER: 1.00e+02, valid WER: 1.00e+02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-17-51+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.56it/s, train_loss=553]\n",
            "100%|██████████| 137/137 [00:08<00:00, 15.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 4, lr: 5.06e-04, steps: 760, optimizer: Adam - train loss: 5.53e+02 - valid loss: 2.95e+02, valid CER: 97.49, valid WER: 1.00e+02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-18-26+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.57it/s, train_loss=521]\n",
            "100%|██████████| 137/137 [00:09<00:00, 14.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 5, lr: 6.33e-04, steps: 950, optimizer: Adam - train loss: 5.21e+02 - valid loss: 2.70e+02, valid CER: 92.37, valid WER: 99.81\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-19-00+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.42it/s, train_loss=470]\n",
            "100%|██████████| 137/137 [00:11<00:00, 11.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 6, lr: 7.59e-04, steps: 1140, optimizer: Adam - train loss: 4.70e+02 - valid loss: 2.41e+02, valid CER: 72.34, valid WER: 94.60\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-19-38+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.50it/s, train_loss=422]\n",
            "100%|██████████| 137/137 [00:12<00:00, 10.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 7, lr: 8.86e-04, steps: 1330, optimizer: Adam - train loss: 4.22e+02 - valid loss: 2.19e+02, valid CER: 66.02, valid WER: 92.37\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-20-17+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.33it/s, train_loss=386]\n",
            "100%|██████████| 137/137 [00:13<00:00, 10.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 8, lr: 9.94e-04, steps: 1520, optimizer: Adam - train loss: 3.86e+02 - valid loss: 2.04e+02, valid CER: 59.76, valid WER: 90.02\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-20-58+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.45it/s, train_loss=358]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 9, lr: 9.37e-04, steps: 1710, optimizer: Adam - train loss: 3.58e+02 - valid loss: 1.92e+02, valid CER: 55.30, valid WER: 88.09\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-21-38+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:26<00:00,  7.29it/s, train_loss=335]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 10, lr: 8.89e-04, steps: 1900, optimizer: Adam - train loss: 3.35e+02 - valid loss: 1.84e+02, valid CER: 52.32, valid WER: 86.52\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-22-20+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.epoch_loop - Going into epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.36it/s, train_loss=317]\n",
            "100%|██████████| 137/137 [00:13<00:00,  9.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 11, lr: 8.47e-04, steps: 2090, optimizer: Adam - train loss: 3.17e+02 - valid loss: 1.77e+02, valid CER: 50.66, valid WER: 85.11\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-23-01+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-16-43+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.34it/s, train_loss=302]\n",
            "100%|██████████| 137/137 [00:15<00:00,  9.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 12, lr: 8.11e-04, steps: 2280, optimizer: Adam - train loss: 3.02e+02 - valid loss: 1.72e+02, valid CER: 47.82, valid WER: 83.89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-23-44+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-17-17+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.34it/s, train_loss=290]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 13, lr: 7.79e-04, steps: 2470, optimizer: Adam - train loss: 2.90e+02 - valid loss: 1.67e+02, valid CER: 45.55, valid WER: 82.94\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-24-26+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-17-51+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.33it/s, train_loss=279]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 14, lr: 7.51e-04, steps: 2660, optimizer: Adam - train loss: 2.79e+02 - valid loss: 1.64e+02, valid CER: 44.70, valid WER: 82.82\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-25-09+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-18-26+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.42it/s, train_loss=270]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 15, lr: 7.26e-04, steps: 2850, optimizer: Adam - train loss: 2.70e+02 - valid loss: 1.61e+02, valid CER: 43.63, valid WER: 81.62\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-25-50+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-19-00+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.31it/s, train_loss=261]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 16, lr: 7.03e-04, steps: 3040, optimizer: Adam - train loss: 2.61e+02 - valid loss: 1.59e+02, valid CER: 42.88, valid WER: 80.84\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-26-32+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-19-38+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:26<00:00,  7.26it/s, train_loss=254]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 17, lr: 6.82e-04, steps: 3230, optimizer: Adam - train loss: 2.54e+02 - valid loss: 1.57e+02, valid CER: 41.72, valid WER: 80.63\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-27-15+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-20-17+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.32it/s, train_loss=247]\n",
            "100%|██████████| 137/137 [00:15<00:00,  9.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 18, lr: 6.62e-04, steps: 3420, optimizer: Adam - train loss: 2.47e+02 - valid loss: 1.55e+02, valid CER: 41.11, valid WER: 79.65\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-27-58+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-20-58+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.37it/s, train_loss=241]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 19, lr: 6.45e-04, steps: 3610, optimizer: Adam - train loss: 2.41e+02 - valid loss: 1.53e+02, valid CER: 40.30, valid WER: 79.66\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-28-42+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-21-38+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:26<00:00,  7.30it/s, train_loss=235]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 20, lr: 6.28e-04, steps: 3800, optimizer: Adam - train loss: 2.35e+02 - valid loss: 1.52e+02, valid CER: 39.84, valid WER: 78.88\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-29-25+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-22-20+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.32it/s, train_loss=230]\n",
            "100%|██████████| 137/137 [00:15<00:00,  9.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 21, lr: 6.13e-04, steps: 3990, optimizer: Adam - train loss: 2.30e+02 - valid loss: 1.51e+02, valid CER: 39.45, valid WER: 78.55\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-30-08+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-23-01+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.36it/s, train_loss=225]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 22, lr: 5.99e-04, steps: 4180, optimizer: Adam - train loss: 2.25e+02 - valid loss: 1.50e+02, valid CER: 39.07, valid WER: 78.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-30-50+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-23-44+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.50it/s, train_loss=221]\n",
            "100%|██████████| 137/137 [00:15<00:00,  9.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 23, lr: 5.86e-04, steps: 4370, optimizer: Adam - train loss: 2.21e+02 - valid loss: 1.49e+02, valid CER: 38.32, valid WER: 77.16\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-31-33+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-24-26+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:26<00:00,  7.27it/s, train_loss=217]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 24, lr: 5.74e-04, steps: 4560, optimizer: Adam - train loss: 2.17e+02 - valid loss: 1.49e+02, valid CER: 38.41, valid WER: 76.58\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-32-16+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-25-09+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.47it/s, train_loss=213]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 25, lr: 5.62e-04, steps: 4750, optimizer: Adam - train loss: 2.13e+02 - valid loss: 1.48e+02, valid CER: 37.87, valid WER: 76.47\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-32-58+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-25-50+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.38it/s, train_loss=209]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 26, lr: 5.51e-04, steps: 4940, optimizer: Adam - train loss: 2.09e+02 - valid loss: 1.48e+02, valid CER: 37.90, valid WER: 76.21\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-33-41+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-26-32+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.40it/s, train_loss=206]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 27, lr: 5.41e-04, steps: 5130, optimizer: Adam - train loss: 2.06e+02 - valid loss: 1.48e+02, valid CER: 37.49, valid WER: 75.74\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-34-23+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-27-15+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.45it/s, train_loss=203]\n",
            "100%|██████████| 137/137 [00:14<00:00,  9.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 28, lr: 5.31e-04, steps: 5320, optimizer: Adam - train loss: 2.03e+02 - valid loss: 1.47e+02, valid CER: 37.24, valid WER: 75.65\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-35-05+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-27-58+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.49it/s, train_loss=200]\n",
            "100%|██████████| 137/137 [00:15<00:00,  8.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 29, lr: 5.22e-04, steps: 5510, optimizer: Adam - train loss: 2.00e+02 - valid loss: 1.47e+02, valid CER: 36.80, valid WER: 75.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-35-48+00\n",
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-28-42+00\n",
            "speechbrain.utils.epoch_loop - Going into epoch 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.52it/s, train_loss=197]\n",
            "100%|██████████| 137/137 [00:15<00:00,  9.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - epoch: 30, lr: 5.13e-04, steps: 5700, optimizer: Adam - train loss: 1.97e+02 - valid loss: 1.46e+02, valid CER: 36.45, valid WER: 75.20\n",
            "speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-36-30+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.checkpoints - Deleted checkpoint in results/transformer/Task_2B/save/CKPT+2024-02-17+16-29-25+00\n",
            "speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 328/328 [00:44<00:00,  7.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "speechbrain.utils.train_logger - Epoch loaded: 30 - test loss: 81.98, test CER: 36.94, test WER: 75.73\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81.97508495028418"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VnWlV2qw2kms"
      },
      "execution_count": 77,
      "outputs": []
    }
  ]
}